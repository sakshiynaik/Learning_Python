{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sakshiynaik/Learning_Python/blob/main/Exercise_Data_Cleaning_Python_Library.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeuSwVw35ToI"
      },
      "source": [
        "# Exercise - Python Library - Data Cleanup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMUMdF7P5ToJ"
      },
      "source": [
        "##### Problem Statement\n",
        "\n",
        "Given a list of dictionaries, each representing a different role, where each dictionary contains a key `'job_skills'` with a string value representing a list of skills, and a `'job_date' represented also in a string value.\n",
        "- Turn the `'job_date'` from a string value to a date time object.\n",
        "- Turn the `'job_skills'` from a string value to an actual list object.\n",
        "\n",
        "\n",
        "First we'll create a list called `data_science_jobs`, containing dictionaries. Each dictionary represents a data science job role:  \n",
        "- `'job_title'`: The title of the job  \n",
        "- `'job_skills'`: A string that represents a list of skills required  \n",
        "- `'job_date'` : A string that represents a date  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dIHsJ26L5ToK"
      },
      "outputs": [],
      "source": [
        "data_science_jobs = [\n",
        "    {'job_title': 'Data Scientist', 'job_skills': \"['Python', 'SQL', 'Machine Learning']\", 'job_date': '2023-05-12'},\n",
        "    {'job_title': 'Machine Learning Engineer', 'job_skills': \"['Python', 'TensorFlow', 'Deep Learning']\", 'job_date': '2023-05-15'},\n",
        "    {'job_title': 'Data Analyst', 'job_skills': \"['SQL', 'R', 'Tableau']\", 'job_date': '2023-05-10'},\n",
        "    {'job_title': 'Business Intelligence Developer', 'job_skills': \"['SQL', 'PowerBI', 'Data Warehousing']\", 'job_date': '2023-05-08'},\n",
        "    {'job_title': 'Data Engineer', 'job_skills': \"['Python', 'Spark', 'Hadoop']\", 'job_date': '2023-05-18'},\n",
        "    {'job_title': 'AI Specialist', 'job_skills': \"['Python', 'PyTorch', 'AI Ethics']\", 'job_date': '2023-05-20'}\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQBU317k5ToL"
      },
      "source": [
        "If we print this variable we can see that the `'job_skills'` and `'job_date'` values are a string."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gacB1YlO5ToM",
        "outputId": "60aafa62-d7e4-4517-ae8b-54373011946a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'job_title': 'Data Scientist', 'job_skills': \"['Python', 'SQL', 'Machine Learning']\", 'job_date': '2023-05-12'}\n"
          ]
        }
      ],
      "source": [
        "print(data_science_jobs[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQLSq1uB5ToN"
      },
      "source": [
        "### `datetime` Conversion (`job_date`)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IOmIOT_5ToN"
      },
      "source": [
        "First let's import datetime in and test it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-npgc8kF5ToN",
        "outputId": "99ea2a95-6464-4308-9a3d-910a8f1c7ae6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "datetime.datetime(2024, 5, 3, 17, 54, 59, 289836)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "# show current date and time\n",
        "datetime.now()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69IgPzZq5ToO"
      },
      "source": [
        "Let's test one value from our `job_date` key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PjGb988t5ToO",
        "outputId": "a8308894-89a4-4915-8e8e-4a21fc370a21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-05-12\n",
            "<class 'str'>\n"
          ]
        }
      ],
      "source": [
        "test_date = data_science_jobs[0]['job_date']\n",
        "\n",
        "print(test_date)\n",
        "print(type(test_date))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_0QdBe_5ToP"
      },
      "source": [
        "We'll now use the `.strptime()` method to convert it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "07KItDD75ToP",
        "outputId": "bf1daad2-0c06-4ee7-82ab-8574919b0f9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-05-12 00:00:00\n"
          ]
        }
      ],
      "source": [
        "print(datetime.strptime(test_date, '%Y-%m-%d'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbhwC2Xr5ToP"
      },
      "source": [
        "It works! Let's convert all them in the list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2LhuyjZ_5ToP",
        "outputId": "a4c74754-b813-46d3-c76a-faeabb7b8240"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'job_title': 'Data Scientist',\n",
              "  'job_skills': \"['Python', 'SQL', 'Machine Learning']\",\n",
              "  'job_date': datetime.datetime(2023, 5, 12, 0, 0)},\n",
              " {'job_title': 'Machine Learning Engineer',\n",
              "  'job_skills': \"['Python', 'TensorFlow', 'Deep Learning']\",\n",
              "  'job_date': datetime.datetime(2023, 5, 15, 0, 0)},\n",
              " {'job_title': 'Data Analyst',\n",
              "  'job_skills': \"['SQL', 'R', 'Tableau']\",\n",
              "  'job_date': datetime.datetime(2023, 5, 10, 0, 0)},\n",
              " {'job_title': 'Business Intelligence Developer',\n",
              "  'job_skills': \"['SQL', 'PowerBI', 'Data Warehousing']\",\n",
              "  'job_date': datetime.datetime(2023, 5, 8, 0, 0)},\n",
              " {'job_title': 'Data Engineer',\n",
              "  'job_skills': \"['Python', 'Spark', 'Hadoop']\",\n",
              "  'job_date': datetime.datetime(2023, 5, 18, 0, 0)},\n",
              " {'job_title': 'AI Specialist',\n",
              "  'job_skills': \"['Python', 'PyTorch', 'AI Ethics']\",\n",
              "  'job_date': datetime.datetime(2023, 5, 20, 0, 0)}]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_science_jobs = [\n",
        "    {'job_title': 'Data Scientist', 'job_skills': \"['Python', 'SQL', 'Machine Learning']\", 'job_date': '2023-05-12'},\n",
        "    {'job_title': 'Machine Learning Engineer', 'job_skills': \"['Python', 'TensorFlow', 'Deep Learning']\", 'job_date': '2023-05-15'},\n",
        "    {'job_title': 'Data Analyst', 'job_skills': \"['SQL', 'R', 'Tableau']\", 'job_date': '2023-05-10'},\n",
        "    {'job_title': 'Business Intelligence Developer', 'job_skills': \"['SQL', 'PowerBI', 'Data Warehousing']\", 'job_date': '2023-05-08'},\n",
        "    {'job_title': 'Data Engineer', 'job_skills': \"['Python', 'Spark', 'Hadoop']\", 'job_date': '2023-05-18'},\n",
        "    {'job_title': 'AI Specialist', 'job_skills': \"['Python', 'PyTorch', 'AI Ethics']\", 'job_date': '2023-05-20'}\n",
        "]\n",
        "from datetime import datetime\n",
        "\n",
        "for job in data_science_jobs:\n",
        "  job['job_date'] = datetime.strptime(job['job_date'], '%Y-%m-%d')\n",
        "\n",
        "data_science_jobs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCATbtCE5ToQ"
      },
      "source": [
        "### `ast` Conversion (`job_skills`)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttPQ_bcb5ToQ"
      },
      "source": [
        "Now let's convert the skills to a list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wHy8dRoK5ToQ",
        "outputId": "17d225ef-da6f-4124-8abb-e9f890128baf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Python', 'SQL', 'Machine Learning']\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_skills = data_science_jobs[0]['job_skills']\n",
        "\n",
        "print(test_skills)\n",
        "type(test_skills)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wje9Uuf95ToQ",
        "outputId": "8a333a25-2efa-4cb7-a055-d4c54b7ec86c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Python', 'SQL', 'Machine Learning']\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import ast\n",
        "\n",
        "print(ast.literal_eval(test_skills))\n",
        "type(ast.literal_eval(test_skills))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xySQ_LjB5ToR"
      },
      "source": [
        "Nice let's do it for all now! (while doing the datetime)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XfRxBjSJ5ToR",
        "outputId": "0fcb9778-7d4d-4312-b175-547c8e9a00cd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'job_title': 'Data Scientist',\n",
              "  'job_skills': ['Python', 'SQL', 'Machine Learning'],\n",
              "  'job_date': datetime.datetime(2023, 5, 12, 0, 0)},\n",
              " {'job_title': 'Machine Learning Engineer',\n",
              "  'job_skills': ['Python', 'TensorFlow', 'Deep Learning'],\n",
              "  'job_date': datetime.datetime(2023, 5, 15, 0, 0)},\n",
              " {'job_title': 'Data Analyst',\n",
              "  'job_skills': ['SQL', 'R', 'Tableau'],\n",
              "  'job_date': datetime.datetime(2023, 5, 10, 0, 0)},\n",
              " {'job_title': 'Business Intelligence Developer',\n",
              "  'job_skills': ['SQL', 'PowerBI', 'Data Warehousing'],\n",
              "  'job_date': datetime.datetime(2023, 5, 8, 0, 0)},\n",
              " {'job_title': 'Data Engineer',\n",
              "  'job_skills': ['Python', 'Spark', 'Hadoop'],\n",
              "  'job_date': datetime.datetime(2023, 5, 18, 0, 0)},\n",
              " {'job_title': 'AI Specialist',\n",
              "  'job_skills': ['Python', 'PyTorch', 'AI Ethics'],\n",
              "  'job_date': datetime.datetime(2023, 5, 20, 0, 0)}]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_science_jobs = [\n",
        "    {'job_title': 'Data Scientist', 'job_skills': \"['Python', 'SQL', 'Machine Learning']\", 'job_date': '2023-05-12'},\n",
        "    {'job_title': 'Machine Learning Engineer', 'job_skills': \"['Python', 'TensorFlow', 'Deep Learning']\", 'job_date': '2023-05-15'},\n",
        "    {'job_title': 'Data Analyst', 'job_skills': \"['SQL', 'R', 'Tableau']\", 'job_date': '2023-05-10'},\n",
        "    {'job_title': 'Business Intelligence Developer', 'job_skills': \"['SQL', 'PowerBI', 'Data Warehousing']\", 'job_date': '2023-05-08'},\n",
        "    {'job_title': 'Data Engineer', 'job_skills': \"['Python', 'Spark', 'Hadoop']\", 'job_date': '2023-05-18'},\n",
        "    {'job_title': 'AI Specialist', 'job_skills': \"['Python', 'PyTorch', 'AI Ethics']\", 'job_date': '2023-05-20'}\n",
        "]\n",
        "\n",
        "import ast\n",
        "from datetime import datetime\n",
        "\n",
        "for job in data_science_jobs:\n",
        "    job['job_date'] = datetime.strptime(job['job_date'], '%Y-%m-%d')\n",
        "    job['job_skills'] = ast.literal_eval(job['job_skills'])\n",
        "\n",
        "data_science_jobs"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "python_course",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}